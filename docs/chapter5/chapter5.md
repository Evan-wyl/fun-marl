# 多智能体强化学习简介



## 算法架构

## Markov Game



## Extensive-form Game



## 学习场景

多智能体强化学习常见场景有**合作场景**、**竞争场景**、**混合场景**。其中，合作场景是指智能体之间处于合作关系；竞争场景是指智能体之间处于竞争关系；混合场景是指智能体之间既有合作关系，也有竞争关系，例如：足球运动中队员之间的关系。

合作场景中，智能体共享相同的奖励函数。在该场景中，MARL算法均以Markov Game为框架。因此，所有智能体具有共同的累积回报、Q函数、价值函数。

竞争场景中，智能体只有两个，且两者处于完全竞争状态，常常被建模为**零和博弈**。在零和博弈场景中，一个智能体的奖励就是另一个智能体的损失，也即$\forall (s,a,s^{`})$，都有

$\frac{1}{N}\sum_{i\epsilon N}R^i (s,a,s^{`})=0$。

混合场景中，

## 挑战



## 算法的类别



## 参考文献

